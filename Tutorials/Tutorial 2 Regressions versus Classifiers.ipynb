{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnijhuis-dnb/Artificial_Intelligence_and_Machine_Learning_for_SupTech/blob/main/Tutorials/Tutorial%202%20Regressions%20versus%20Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9uRovz0R8V"
      },
      "source": [
        "## DNB Academie: Machine Learning â€“ Tools and applications for policy \n",
        "Tutorial 2: Regressions versus Classifiers\n",
        "*\tLogit as a statistical model vs ML model\n",
        "*\tHow to find the optimal (hyper)parameters\n",
        "*\tA different classifier: Support vector machines \n",
        "  *\tDifferent types of kernels\n",
        "  *\tFirst glimpse: Dangers of overfitting\n",
        "  *\tEvaluating performance\n",
        "\n",
        "<br/>\n",
        "\n",
        "15 & 22 Jan 2024  \n",
        "\n",
        "**Instructors**  \n",
        "Prof. Iman van Lelyveld (iman.van.lelyveld@vu.nl)<br/>\n",
        "Dr. Michiel Nijhuis (m.nijhuis@dnb.nl)  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Whl7phFpqJR8"
      },
      "source": [
        "----"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqaAXvSoHWGO"
      },
      "source": [
        "# Preparation\n",
        "\n",
        "At the beginning of each notebook, we have a short preparation section. This section will do three things. First of all it will loads all the necessary packages or download and install them. Secondly it will also download and extract the data we are going to use during the tutorial. The third thing is to run most of the code from the previous notebook so we can continue working with the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_colab = False\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  in_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gdown==4.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAUm1PTv3Y5I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSmrbk7jEnVo"
      },
      "outputs": [],
      "source": [
        "!gdown 1-3c9BhPfl6D92HvTI4kNd0MfmTquiUwQ\n",
        "!gdown 1-5ZzK3EAqc-i3AgnLOSZXTGGZsEPEmzH"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Fic-DPeTKChS"
      },
      "source": [
        "### Tutorial 1\n",
        "In this section we re-run most of the code from tutorial 1. This setups up the data so we can use it for this tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmnE663Kw5n2"
      },
      "outputs": [],
      "source": [
        "if in_colab:\n",
        "    df_record = pd.read_csv('/content/credit_record.csv')\n",
        "    df_applications = pd.read_csv('/content/application_record.csv')\n",
        "else:\n",
        "    df_record = pd.read_csv('credit_record.csv')\n",
        "    df_applications = pd.read_csv('application_record.csv')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rVTrcMP0jpt"
      },
      "outputs": [],
      "source": [
        "df_record.loc[:,'status'] = df_record.loc[:,'STATUS']\n",
        "df_record.loc[:,'status'] = df_record.loc[:,'status'].replace('X', '0')\n",
        "df_record.loc[:,'status'] = df_record.loc[:,'status'].replace('C', '0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM0qCRyr0pJ9"
      },
      "outputs": [],
      "source": [
        "df_record.loc[:,'status'] = pd.to_numeric(df_record.loc[:,'status'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM5_vBLA3KSb"
      },
      "outputs": [],
      "source": [
        "sr_defaults = df_record.groupby('ID')['status'].agg(lambda x: sum(x>=2)>0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L18eOAdA4eu"
      },
      "outputs": [],
      "source": [
        "df_applications = df_applications.drop_duplicates(subset='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2wh3U3X3d7k"
      },
      "outputs": [],
      "source": [
        "df_applications = df_applications.set_index('ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5LpPaJE8L68"
      },
      "outputs": [],
      "source": [
        "df_applications = df_applications.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdixnHsgVKCA"
      },
      "outputs": [],
      "source": [
        "obj_cols = df_applications.select_dtypes(include=['object']).columns.tolist()\n",
        "dummies_list = [pd.get_dummies(df_applications[col], prefix=col, drop_first=True) for col in obj_cols]\n",
        "df_applications = pd.concat([df_applications.drop(columns=obj_cols)] + dummies_list, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50Uo0hr-VbJB"
      },
      "outputs": [],
      "source": [
        "df_data = df_applications.merge(sr_defaults, how='inner', left_index=True, right_on='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCZHB6vhWPqx"
      },
      "outputs": [],
      "source": [
        "df_data= df_data.rename(columns={'status':'DEFAULTED'}).dropna()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "45ZZYB8xV-Ip"
      },
      "source": [
        "## Data analysis\n",
        "Before we can make our model we first have to apply some data analysis to get a better understanding of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kps7R8evDQXZ"
      },
      "outputs": [],
      "source": [
        "df_corr = df_data.corr()\n",
        "df_corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcKk3V_FKDcF"
      },
      "outputs": [],
      "source": [
        "df_corr.loc['DEFAULTED'].sort_values(ascending=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1FKRhDl6F5UI"
      },
      "source": [
        "# Linear Regression\n",
        "Now we can apply our linear regression model, both from sklearn (which takes more of a machine learning view) and for statsmodels (which takes more of an econometrics view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0YwOfy5F_uh"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QHQVCOaxE5m7"
      },
      "source": [
        "Select the columns that you want to use for the regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFMuANZ0E9Jl"
      },
      "outputs": [],
      "source": [
        "exogenous_collumns = []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iDVh9CsmFPv1"
      },
      "source": [
        "Get the data ready for the regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yvYSJfqF7Yk"
      },
      "outputs": [],
      "source": [
        "sr_endog = df_data.loc[:,'DEFAULTED'].astype(float)\n",
        "\n",
        "df_exogs = df_data[exogenous_collumns]\n",
        "df_exogs = sm.add_constant(df_exogs)\n",
        "df_exogs.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lEjpN_SiamWx"
      },
      "source": [
        "## Econometric view: with `statsmodels`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jTihRQiGIcs"
      },
      "outputs": [],
      "source": [
        "linreg_sm = sm.OLS(\n",
        "    endog=sr_endog,\n",
        "    exog=df_exogs,\n",
        ").fit()\n",
        "\n",
        "print(linreg_sm.summary())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tYd3dXa4ar40"
      },
      "source": [
        "## Machine learning: with `scikit-learn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EN2luwybHqe"
      },
      "outputs": [],
      "source": [
        "X = df_exogs.values\n",
        "y = sr_endog.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ_29PnIavLz"
      },
      "outputs": [],
      "source": [
        "linreg_ml = LinearRegression(fit_intercept=False)\n",
        "linreg_ml.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyr5soYYa5iR"
      },
      "outputs": [],
      "source": [
        "linreg_ml.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPmmHO_8a7AZ"
      },
      "outputs": [],
      "source": [
        "linreg_ml.score(X, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zvnbS3yzN-oY"
      },
      "source": [
        "# Classification\n",
        "\n",
        "Until now we have used linear regressions to best predict the outcome. The results are very poor. With $R^2$ of 3-4%, there is little hope for this to continue well, especially if we are concerned about \"external validity\". \n",
        "\n",
        "This is not surprising since we do not have a regression problem. Instead, the outcome is binary. We are not that much interested in a trend or \"regressing toward the mean\". A better approach is classification, so we can use logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj7AI2luYzs4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs24v8r6Yzs4"
      },
      "outputs": [],
      "source": [
        "mdl_logit = LogisticRegression(fit_intercept=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hvH1UHN7GO0v"
      },
      "source": [
        "Fit the logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocxGaKrpGewg"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TnxEW8OZGZ-t"
      },
      "source": [
        "Make prediction for the all the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDmetwy3GfUr"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E6C8oY-fH1Wy"
      },
      "source": [
        "Assess the performance of the logit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwHmQZp2H2Ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tOCxeVjVIFGT"
      },
      "source": [
        "### Support Vector Machine\n",
        "The next step is to use a SVM to predict the classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAHQJ8OBIUmu"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjvY69J-Yzs5"
      },
      "outputs": [],
      "source": [
        "clf = SVC(C=1.0, \n",
        "          kernel='rbf', \n",
        "          degree=3, \n",
        "          gamma='scale', \n",
        "          coef0=0.0, \n",
        "          shrinking=True, \n",
        "          probability=False, \n",
        "          tol=0.1, \n",
        "          cache_size=200, \n",
        "          class_weight=None, \n",
        "          verbose=False, \n",
        "          max_iter=20, \n",
        "          decision_function_shape='ovr', \n",
        "          break_ties=False, \n",
        "          random_state=43)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B6mUMrp8MIfs"
      },
      "source": [
        "Fit the data to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc7C0IfEBaAY"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ci-OLnVKNHNF"
      },
      "source": [
        "Make a prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO2w1k8dNHr-"
      },
      "outputs": [],
      "source": [
        "y_model = clf.predict(X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P4vyqEDkMLB7"
      },
      "source": [
        "Calculate the recall and the precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7QFZcJHMwvh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score, precision_score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kVcWclGyNqWk"
      },
      "source": [
        "Calculate the prediction yourself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEU1HV_7MUmv"
      },
      "outputs": [],
      "source": [
        "recall = recall_score(y,y_model)\n",
        "\n",
        "print(f'The recall is:{recall} \\t The precision is: ')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ovBmcOzboI"
      },
      "source": [
        "The following code is a function to plot the decision boundary of a SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "texQG5y4zcHW"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "\n",
        "def plot_decision_boundary(model: SVC, \n",
        "                           data_x: pd.DataFrame, \n",
        "                           data_y: pd.Series) -> None:\n",
        "    \"\"\"\n",
        "    Plot the decision boundary of a classifier using the given data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : sklearn.svm.SVC\n",
        "        The classifier to use for generating the decision boundary.\n",
        "    data_x : pandas.DataFrame\n",
        "        The input data to use for generating the decision boundary.\n",
        "    data_y : pandas.Series\n",
        "        The target values to use for generating the decision boundary.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        This function does not return anything, but it generates a plot of the decision boundary.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def make_meshgrid(x_in: pd.Series, \n",
        "                      y_in: pd.Series) -> tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Generate a meshgrid based on the given x and y series.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x_in : pandas.Series\n",
        "            Input x values.\n",
        "        y_in : pandas.Series\n",
        "            Input y values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tuple[np.ndarray, np.ndarray]\n",
        "            A tuple of two NumPy arrays representing the meshgrid generated from x and y values.\n",
        "            The first array represents the x-coordinates and the second array represents the y-coordinates.\n",
        "        \"\"\"\n",
        "        x_min, x_max = x_in.min() - 1, x_in.max() + 1\n",
        "        y_min, y_max = y_in.min() - 1, y_in.max() + 1\n",
        "        x, y = np.meshgrid(np.arange(x_min, x_max, (x_max - x_min)/100), \n",
        "                           np.arange(y_min, y_max, (y_max - y_min)/100))\n",
        "        \n",
        "        return x, y\n",
        "\n",
        "    def plot_contours(ax: mpl.axes.Axes, \n",
        "                      clf: SVC, \n",
        "                      xx: np.array, \n",
        "                      yy: np.array, \n",
        "                      **kwargs) -> mpl.figure.Figure:\n",
        "        \"\"\"\n",
        "        Plot the decision boundaries for a classifier.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        ax : matplotlib.axes.Axes\n",
        "            The axes on which to plot the decision boundaries.\n",
        "        clf : sklearn.svm.SVC\n",
        "            The classifier to use for generating the decision boundaries.\n",
        "        xx : numpy.ndarray\n",
        "            The x values for the meshgrid used to generate the decision boundaries.\n",
        "        yy : numpy.ndarray\n",
        "            The y values for the meshgrid used to generate the decision boundaries.\n",
        "        **kwargs : Dict[str,Any]\n",
        "            Additional keyword arguments to pass to the `contourf` method.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        matplotlib.figure.Figure\n",
        "            The figure object returned by the `contourf` method.\n",
        "        \"\"\"\n",
        "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "        Z = Z.reshape(xx.shape)\n",
        "        out = ax.contourf(xx, yy, Z, **kwargs)\n",
        "        return out\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    x, y = make_meshgrid(data_x[:, 0], data_x[:, 1])\n",
        "\n",
        "    ax.scatter(data_x[:, 0], \n",
        "               data_x[:, 1], \n",
        "               c=data_y, \n",
        "               cmap=plt.cm.coolwarm, \n",
        "               s=20)\n",
        "    plot_contours(ax, \n",
        "                  model, \n",
        "                  x, \n",
        "                  y, \n",
        "                  cmap=plt.cm.coolwarm, \n",
        "                  alpha=0.4)\n",
        "    ax.set_ylabel(data_x.columns[0])\n",
        "    ax.set_xlabel(data_x.columns[1])\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    ax.set_title('Decision boundary SVC ')\n",
        "\n",
        "    return None"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RnvmWi3l48Yr"
      },
      "source": [
        "Redo the prediction with just a couple of variables, so we can plot the decision boundary and see the effect of different kernels. You can use the following kernels: 'linear', 'poly', 'rbf', 'sigmoid' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0fU5CWs4QIn"
      },
      "outputs": [],
      "source": [
        "clf = SVC(kernel='linear', \n",
        "          degree=3, \n",
        "          gamma='scale', \n",
        "          coef0=0.0, \n",
        "          shrinking=True, \n",
        "          probability=False, \n",
        "          tol=0.1, \n",
        "          cache_size=200, \n",
        "          class_weight=None, \n",
        "          verbose=False, \n",
        "          max_iter=20, \n",
        "          decision_function_shape='ovr', \n",
        "          break_ties=False, \n",
        "          random_state=43)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bpgfIGju5FQJ"
      },
      "source": [
        "Select the two columns which you will use for the model and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeazfuLh5Bj1"
      },
      "outputs": [],
      "source": [
        "two_selected_columns = []\n",
        "\n",
        "clf = clf.fit(X[two_selected_columns], y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tFIXZ-Dy5jn4"
      },
      "source": [
        "Plot the decision boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yZ5B9j04851"
      },
      "outputs": [],
      "source": [
        "plot_decision_boundary(clf, X, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TgnPS0XN5hni"
      },
      "source": [
        "Adjust the kernel and see the effects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8b155lp5hQS"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yNSGUrcsOxUN"
      },
      "source": [
        "Changing the model to get a better prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPUA1p3MOw5Q"
      },
      "outputs": [],
      "source": [
        "clf = SVC(C=1.0, \n",
        "          kernel='poly', \n",
        "          degree=30, \n",
        "          gamma='scale', \n",
        "          coef0=0.0, \n",
        "          shrinking=True, \n",
        "          probability=False, \n",
        "          tol=0.0001, \n",
        "          cache_size=200, \n",
        "          class_weight=None, \n",
        "          verbose=False, \n",
        "          max_iter=-1, \n",
        "          decision_function_shape='ovr', \n",
        "          break_ties=False, \n",
        "          random_state=43)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mf-NbLJgPAMa"
      },
      "source": [
        "See how the prediction is changed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp-uiSJ3O_4h"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "67QcM4GgPfNH"
      },
      "source": [
        "Do you think this is a good prediction?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HtnjSnFJPmVb"
      },
      "source": [
        "Can you select better parameters for the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_bB5OVtPeyS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
