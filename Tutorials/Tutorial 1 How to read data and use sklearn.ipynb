{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnijhuis-dnb/Artificial_Intelligence_and_Machine_Learning_for_SupTech/blob/main/Tutorials/Tutorial%201%20How%20to%20read%20data%20and%20use%20sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9uRovz0R8V"
      },
      "source": [
        "## DNB Academie: Machine Learning – Tools and applications for policy \n",
        "Tutorial 1: How to read data and use sklearn\n",
        "*\tGetting started with Python and data manipulation. \n",
        "*\tHow is this different from Excel?\n",
        "*\tRead the data and get to know it. \n",
        "*\tIntroduction to sklearn: where to ﬁnd the buttons\n",
        "\n",
        "<br/>\n",
        "\n",
        "15 & 22 Jan 2024\n",
        "\n",
        "**Instructors**  \n",
        "Prof. Iman van Lelyveld (iman.van.lelyveld@vu.nl)<br/>\n",
        "Dr. Michiel Nijhuis (m.nijhuis@dnb.nl)  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Whl7phFpqJR8"
      },
      "source": [
        "----"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SgRY6vyVRdgA"
      },
      "source": [
        "###Notebooks\n",
        "The tutorials in this course will be performed using notebooks. If you are unfamiliar with running code from a notebook you can follow this section to get acquainted with using notebooks."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tetHEmyercEF"
      },
      "source": [
        "A Jupyter notebook is made up of a number of cells. Each cell can contain Python code. There are two main types of cells: `Code` cells and `Markdown` cells. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndic1dymre-i"
      },
      "source": [
        "#### Code cells\n",
        "Code cells are used to write and execute code. To create a new code cell, click the \"+ Code\" button in the toolbar or when hovering over the bottom of another cell with your mouse.\n",
        "\n",
        "To run a code cell, select the cell and click the _play_ button on the top left corner of the cell or press \"Shift + Enter\" on your keyboard. To run multiple cells at once, you can use the \"Runtime\" selection on the toolbar. The output of the last line of the code cell will be displayed below the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30Om2QWORbjW"
      },
      "outputs": [],
      "source": [
        "x = 4\n",
        "x * 1.2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ilyeZryotI12"
      },
      "source": [
        "Once a cell ran, the changes to the variables are stored. So we can now change the value of _x_ by using the variable in the next cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrL4xElytdY2"
      },
      "outputs": [],
      "source": [
        "x = x * 2 \n",
        "x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lR3C-TnxthOO"
      },
      "source": [
        "The order in which the cell are executed in the notebook does matter, if we were to execute the cell below we would get 5 as an answer, if we just excuted the first two cells. If after executing the first two cells we executed the first cell again we would get 1 as an answer as the value of _x_ was reset to 4. Go give it a try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv-PfLVDtz0w"
      },
      "outputs": [],
      "source": [
        "x - 3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P5TFDrGyustO"
      },
      "source": [
        "#### Markdown Cells\n",
        "Markdown cells are used to write formatted text, such as headings, lists, and links. This is an example of a markdown cell. The markdown cells can be created in a similar way as code cells. The markdown cells can be used to write comments on your code and make your notebook more structured and understandable for others."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqaAXvSoHWGO"
      },
      "source": [
        "### Preparation\n",
        "\n",
        "At the beginning of each notebook, we have a short preparation section. This section will do two things. First of all it will loads all the necessary packages or download and install them. Secondly it will also download and extract the data we are going to use during the tutorial."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NW-TXfiLvTii"
      },
      "source": [
        "The first step is to going to load some of the general packages we are going to use throughout the notebook. These are the following packages:\n",
        "* **Pandas** &emsp;&ensp;&nbsp; A package for data manipulation and analysis\n",
        "* **Numpy** &emsp;&emsp; A package for doing numerical calculations\n",
        "* **Matplotlib** &ensp; A package for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAUm1PTv3Y5I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UvOHCcxDyldS"
      },
      "source": [
        "Next we are going to retrieve some data from, we are going to do this by using an exclamation mark to start our commands. This will send the commands to the terminal instead of using the Python interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoWyKyi8vR4T"
      },
      "outputs": [],
      "source": [
        "!gdown 1-3c9BhPfl6D92HvTI4kNd0MfmTquiUwQ\n",
        "!gdown 1-5ZzK3EAqc-i3AgnLOSZXTGGZsEPEmzH"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "inlbKvZ7yCa0"
      },
      "source": [
        "# Credit card defaults\n",
        "\n",
        "For the first 3 tutorials we will try to predict whether a credit card debtor will default on his loan. We will do this by using the following datasets:\n",
        "* `credit_record.csv`  \n",
        "contains the monthly credit card status (paid off, overdue, written off, no loan). Each entry has a unique client number `ID`\n",
        "* `application_record.csv`  \n",
        "contains meta data about each client (gender, owns property, education, marital stats,...). Each client is also identified with the unique client number `ID`\n",
        "\n",
        "Let's have a look at both. In each case, we want to know how many records there are in total and how the first couple of rows look like."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f36-qJ8GyIci"
      },
      "source": [
        "# Make the labels: `df_records`\n",
        "The goal of this section is to define what the goal of the predictions are. In this case we want to predict whether or not a client defaults on their credit card.\n",
        "\n",
        "At this point we only focus on `df_records` and will get back to `df_applications` later. In the remainder of this notebook we will use `sr_defaults` as the outcome variable. In machine learning, the default status is often referred to as the label. In statistics or econometrics, this would be the dependent, endogenous or left-hand side variable.\n",
        "\n",
        "The remaining columns of `df_applications` are the features. Alternatively, we call them predictors, exogenous variables or right-hand side variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmnE663Kw5n2"
      },
      "outputs": [],
      "source": [
        "path = 'credit_record.csv'\n",
        "df_record = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhSpaWklVFvm"
      },
      "outputs": [],
      "source": [
        "df_record"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b9JoD4f3ziED"
      },
      "source": [
        "Each client has a credit card that can used each month. \n",
        "\n",
        "The columns\n",
        "* `MONTHS_BALANCE` is a time indicator. When it is `0` it refers to the current month. When it is `-1` it refers to last month, and so on. \n",
        "* `STATUS` tells us what the status of the credit card debt is. The possible values are\n",
        "\n",
        "```\n",
        "X: no loan\n",
        "C: paid off\n",
        "0: overdue <1 month\n",
        "1: overdue 1 months\n",
        "2: overdue 2 months\n",
        "3: overdue 3 months\n",
        "4: overdue 4 months\n",
        "5: overdue 5 months or more (written-off)\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OSZ-nCVD07IC"
      },
      "source": [
        "## What are DataFrames?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p6s0_XT_y6_t"
      },
      "source": [
        "These are what we call DataFrames. They are a flexible and powerful data storage unit and one of the main reasons for Python's popularity. Think of it as containing an excel spreadsheet. It contains rows, columns and cells. For those familiar with relational databases, you can also think of these as tables. What is powerful about DataFrames is that it automates what you usually do in Excel."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P9rSOHsY1KmN"
      },
      "source": [
        "## Navigating DataFrames\n",
        "\n",
        "\n",
        "Let us start by selecting the credit card status of client `5001713`. For this purpose we can tell the dataframe to use the column `ID` as the index. An index is like the \"name\" of the row, such that we can more easily refer to it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHuPcJddy5gW"
      },
      "outputs": [],
      "source": [
        "df_record = df_record.set_index('ID')\n",
        "df_record.head(10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfh9RmfS0AmF"
      },
      "source": [
        "To select a row (or rows) by the client number `ID`, we use the `.loc` operator. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7T3LUQ-0D8V"
      },
      "outputs": [],
      "source": [
        "df_record.loc[5001713]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r7m-q2ht4efW"
      },
      "source": [
        "As our index is now not unique, we change it back to row numbers, in that way each row can be uniquely identified by its row number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeHTBc9c4eIO"
      },
      "outputs": [],
      "source": [
        "df_record = df_record.reset_index(drop=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0q_t92xE0Fw_"
      },
      "source": [
        "We can also select entire columns. For this we need to tell python to select all rows (`:`) of a specific column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddfgsflz0G5e"
      },
      "outputs": [],
      "source": [
        "df_record.loc[:,'STATUS']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YvXx9U4r0JBc"
      },
      "source": [
        "Finally, we can also select the statuses of a specific client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlAzL1y60KT2"
      },
      "outputs": [],
      "source": [
        "df_record.loc[df_record['ID']==5001713,'STATUS']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-DuBRFo10MNJ"
      },
      "source": [
        "##  Renaming columns and values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VkyFLJIx0Q9v"
      },
      "source": [
        "The columns `MONTHS_BALANCE` and `STATUS` are given. Let create new columns that are more easily readable and easier to plot. \n",
        "\n",
        "For `MONTHS_BALANCE`, we only want to give it a different name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnK0p8kX0TvI"
      },
      "outputs": [],
      "source": [
        "df_record = df_record.rename(columns={'MONTHS_BALANCE': 'month'})\n",
        "df_record.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7FZeDTD90biw"
      },
      "source": [
        "For `STATUS`, we want to not only rename it, but also convert it to numeric values. Recall that the possible values are\n",
        "\n",
        "```\n",
        "X: no loan\n",
        "C: paid off\n",
        "0: overdue <1 month\n",
        "1: overdue 1 months\n",
        "2: overdue 2 months\n",
        "3: overdue 3 months\n",
        "4: overdue 4 months\n",
        "5: overdue 5 months or more (written-off)\n",
        "```\n",
        "\n",
        "This means, it has strings (`X` or `C`) as well as integers (`0,1,...5`). For our purposes, we do not need to differentiate whether the client has status `X: no loan` or `'C: paid off` or is `0: overdue <1 month`. Let us therefore convert `X` and `C` to `0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rVTrcMP0jpt"
      },
      "outputs": [],
      "source": [
        "df_record.loc[:,'status'] = df_record.loc[:,'STATUS']\n",
        "df_record.loc[:,'status'] = df_record.loc[:,'status'].replace('X', '0')\n",
        "df_record.loc[:,'status'] = df_record.loc[:,'status'].replace('C', '0')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QGvTUlIT0msP"
      },
      "source": [
        "Now we can tell the column to be integers instead of strings."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LyAOuon_1Cyx"
      },
      "source": [
        "The column now only contains integers, but these are still stored as strings. By looking at the dtypes attribute of the dataframe. Note that dtypes is an attribute of the dataframe not a method, so no round brackets are needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NiE8aQY02kf"
      },
      "outputs": [],
      "source": [
        "df_record.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM0qCRyr0pJ9"
      },
      "outputs": [],
      "source": [
        "df_record.loc[:,'status'] = pd.to_numeric(df_record.loc[:,'status'])\n",
        "df_record.dtypes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "foWqb4B70rA_"
      },
      "source": [
        "This is important because we want to plot the results in the next step. If the values are stored as strings `'0'` rather than integers `0`, the plotter wouldn't know how to plot `'0'` just like it wouldn't know how to plot the letter `C`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qWsCU4s-1RA4"
      },
      "source": [
        "## Visually inspect the results\n",
        "The next step in the data analysis process is to visually inspect the data in the records. To do this we are going to use the _matplotlib_ package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-OWaOMr1o9g"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuA3TZCX1UJ6"
      },
      "outputs": [],
      "source": [
        "client_id = 5112594\n",
        "\n",
        "x = df_record.loc[df_record['ID']==client_id, 'month']\n",
        "y = df_record.loc[df_record['ID']==client_id, 'status']\n",
        "\n",
        "plt.plot(x, y, marker='o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7CChNK91r8h"
      },
      "outputs": [],
      "source": [
        "client_id = 5112599\n",
        "\n",
        "x = df_record.loc[df_record['ID']==client_id, 'month']\n",
        "y = df_record.loc[df_record['ID']==client_id, 'status']\n",
        "\n",
        "plt.plot(x, y, marker='o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPEKG4BU1t_2"
      },
      "outputs": [],
      "source": [
        "client_id = 5085886\n",
        "plt.plot(df_record.loc[df_record['ID']==client_id, 'month'], \n",
        "         df_record.loc[df_record['ID']==client_id, 'status'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X2AM6rqM139x"
      },
      "source": [
        "## Create variable `DEFAULTED`\n",
        "\n",
        "For our later exercise of classifying and predicting clients based on their application characteristics in `df_applicaitons`, we want to summarize the time series of each client to one variable, which captures: Did the client default at some point?\n",
        "\n",
        "Since the column `status` contains all necessary information, all we need to do is to ask: Was the `status` at any point higher or equal than `3`? That is, was the client at any point past due more than 90 days? \n",
        "\n",
        "To make life easier, let us first select the history of one client that we know to have defaulted and one that did not. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LizK8n7Q2BWu"
      },
      "outputs": [],
      "source": [
        "bad_client_id = 5085886\n",
        "good_client_id = 5112594"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0WfUIYzO2Cvf"
      },
      "source": [
        "### Bad client\n",
        "\n",
        "Since we want to know a client defaulted at **any** point, we do not need the months anymore. We only need to select one column. In such a case, there is no need for a full dataframe. Instead, a Series suffices.\n",
        "\n",
        "Series are to DataFrames what vectors are to matrices. They are simpler and only 1-dimensional. You can decompose a DataFrame into Series and build a DataFrame out of Series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHoDg99g2d-m"
      },
      "outputs": [],
      "source": [
        "bad_client = df_record.loc[df_record['ID']==bad_client_id, 'status']\n",
        "bad_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0oAoFck2htx"
      },
      "outputs": [],
      "source": [
        "client_defaulted = bad_client >= 2\n",
        "client_defaulted"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sj9nopE-2jFz"
      },
      "source": [
        "Note that we now know if the client defaulted in each month, but this is not yet aggregated. We only want to know if any **any** point, the client defaulted. One way to ask this question is to count the number of `True` values and ask whether this total count is larger than `0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6idYrVJ2pXq"
      },
      "outputs": [],
      "source": [
        "client_defaulted.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYjAdv_J734N"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.linspace(0,1,61), client_defaulted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSVLYUoB2qrA"
      },
      "outputs": [],
      "source": [
        "client_defaulted.sum() > 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K3TylZxg2sqD"
      },
      "source": [
        "### Good client\n",
        "For a good client, the result should be `False`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkZ0ATCk20i_"
      },
      "outputs": [],
      "source": [
        "good_client = df_record.loc[df_record['ID']==good_client_id, 'status']\n",
        "client_not_defaulted = good_client >= 2\n",
        "client_not_defaulted.sum() > 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc9ddn_822mt"
      },
      "source": [
        "### Automation: define a function\n",
        "Now we want to see for all the clients if they defaulted or not, first lets check how many clients there are"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62wuTlqE33Vf"
      },
      "outputs": [],
      "source": [
        "len(df_record.ID.unique())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vES54zsW34il"
      },
      "source": [
        "Given that there are 45,985 unique clients, we do not want to do this manually. As we will see, we can do this in just one step later one. But first, let us automate the last tasks we did: Did a client default at any point?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXylkdTg27vY"
      },
      "outputs": [],
      "source": [
        "def was_there_a_default(client_id: int, df_record: pd.DataFrame) -> bool:\n",
        "    \"\"\" Determines if there was a default at the specific client_id in the df_record dataframe\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      client_id: int\n",
        "      The client id for which the function checks if there is a default\n",
        "\n",
        "      df_record: pd.DataFrame\n",
        "      The dataframe containing the records of he clients\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "      bool\n",
        "      A boolean which is true if the client has defaulted on the loan\n",
        "    \"\"\"\n",
        "    defaulted = df_record.loc[df_record['ID']==client_id, 'status'] >= 2\n",
        "    return defaulted.sum() > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVw3babL2-Tz"
      },
      "outputs": [],
      "source": [
        "was_there_a_default(good_client_id, df_record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzy8Hy_x2_V0"
      },
      "outputs": [],
      "source": [
        "was_there_a_default(bad_client_id, df_record)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qsILfxWt3Bcg"
      },
      "source": [
        "### Automation: Apply the function across all clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM5_vBLA3KSb"
      },
      "outputs": [],
      "source": [
        "IDs = df_record.loc[:,'ID'].unique()\n",
        "defaults = []\n",
        "for ID in IDs[:1000]:\n",
        "  defaults.append(was_there_a_default(ID, df_record))\n",
        "\n",
        "defaults"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LnsfwCBx74He"
      },
      "source": [
        "We can do that faster by avoiding the loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IatXDjhX7qbk"
      },
      "outputs": [],
      "source": [
        "sr_defaults = df_record.groupby('ID')['status'].agg(lambda x: sum(x>=2)>0)\n",
        "sr_defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnMoAT3G3N1K"
      },
      "outputs": [],
      "source": [
        "sr_defaults.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vUZSjBN3P93"
      },
      "outputs": [],
      "source": [
        "sr_defaults.value_counts().plot.bar()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UZo4MNoKjeFp"
      },
      "source": [
        "### Sidebar: What is `groupby`?\n",
        "One of the most useful features of Series (and DataFrames) is the `groupby` method. It groups all rows with the same index together and applies a function to each of the groups as if they were separate Series. Afterwards, it glues them together again.\n",
        "\n",
        "For instance, if we have this simple series\n",
        "```\n",
        ">>> sr \n",
        "ID\n",
        "A    0\n",
        "A    1\n",
        "A    1\n",
        "B    1\n",
        "B    0\n",
        "```\n",
        "we can then run the command `sr.groupby('ID').sum()`. This will first split them into two \"subseries\"\n",
        "```\n",
        "A = [0, 1, 1]\n",
        "B = [1, 0]\n",
        "```\n",
        "to which it then applies the function `sum` to\n",
        "```\n",
        "A = f([0, 1, 1])\n",
        "B = f([1, 0])\n",
        "```\n",
        "The result would then be\n",
        "```\n",
        ">>> sr.groupby('ID').sum()\n",
        "ID\n",
        "A    2\n",
        "B    1\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9gR_yyJ8qfJa"
      },
      "source": [
        "----"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k_dMX4Y-3YFX"
      },
      "source": [
        "## Applications\n",
        "Now we are going to look at applications data. Can you preprocess this data so that we can use it going forward? If we want to use the data, all the columns we want to use in the model should be numeric values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeVVgitMy_kF"
      },
      "outputs": [],
      "source": [
        "path = 'application_record.csv'\n",
        "df_applications = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlXnUP44zDeI"
      },
      "outputs": [],
      "source": [
        "df_applications.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zo8JW5a1DLH3"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OjUkGSqe6Cab"
      },
      "source": [
        "## Adding the defaults to the applications\n",
        "\n",
        "Now it is time to merge both `sr_defaults` and `df_applications`. Using the latter as the main DataFrame, we merge `sr_defaults` into it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o30Qf8lIBzV-"
      },
      "outputs": [],
      "source": [
        "df_data = df_applications.merge(sr_defaults, how='inner', left_on='ID', right_on='ID')\n",
        "df_data = df_data.rename(columns={'status':'DEFAULTED'})\n",
        "df_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4ricB7Kqzi0"
      },
      "source": [
        "----"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0BLVvmX_EgIG"
      },
      "source": [
        "## SKLearn\n",
        "Now we have the data, we can already try to apply a machine learning model to it. To do this we can use SKLearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFCSRxcyEf63"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FtsNoraDGKh5"
      },
      "source": [
        "Define a Elestic Net function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n0AI3rAF9-9"
      },
      "outputs": [],
      "source": [
        "enet = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=46)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FkAQMYqyGNz9"
      },
      "source": [
        "Train the Elestic net on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSMFul8SGhKU"
      },
      "outputs": [],
      "source": [
        "df_data_x= df_data.drop(columns='DEFAULTED')\n",
        "df_data_y = df_data['DEFAULTED']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XghDk8xGRF1"
      },
      "outputs": [],
      "source": [
        "enet.fit(df_data_x, df_data_y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eUfJjOzRGub-"
      },
      "source": [
        "Now that the elastic net is trained we can make prediction based on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMabBHHBHD9T"
      },
      "outputs": [],
      "source": [
        "enet.predict(df_data_x.iloc[:5,:])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tSwTIxOzIopR"
      },
      "source": [
        "This is not the way you should generally make these predictions, we are training on the same data we are making the predictions on, we did not remove the unbalance from the data among others. In later tutorials we will make a better prediction. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "1487036e2b4c3efb4b3c8f354d2634a52c03b8f86cae8ff8f4b4aaa5461f93fb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
